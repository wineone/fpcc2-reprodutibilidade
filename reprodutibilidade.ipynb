{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aluno: Matheus Lisboa Oliveira dos Santos\n",
    "### Matrícula: 0123025804-7M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h612Vlc9pPTQ"
   },
   "source": [
    "### Paper\n",
    "- https://aclanthology.org/D19-5821.pdf\n",
    "\n",
    "### Code\n",
    "- https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esse artigo descreve a utilização do modelo de linguagem T5 para a geração de questões. Foi utilizada a base de dados SQuAD para a avaliação. Para a reprodutibilidade utilizaremos os modelo T5 small, por limitações de hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh-mNUZZ_5ab"
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get install python3.7\n",
    "\n",
    "# !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
    "\n",
    "# !sudo update-alternatives --config python3\n",
    "\n",
    "# !sudo apt install python3-pip\n",
    "\n",
    "# !python --version\n",
    "\n",
    "# !sudo apt-get install python3.7-distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2KM0iXtgpPIp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==3.0.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: nltk in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (3.7)\n",
      "Requirement already satisfied: nlp==0.2.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers==0.8.0-rc4 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (0.8.0rc4)\n",
      "Requirement already satisfied: sacremoses in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (0.0.53)\n",
      "Requirement already satisfied: numpy in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (1.21.5)\n",
      "Requirement already satisfied: packaging in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (21.3)\n",
      "Requirement already satisfied: filelock in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (3.6.0)\n",
      "Requirement already satisfied: requests in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (2.28.1)\n",
      "Requirement already satisfied: sentencepiece in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers==3.0.0) (0.2.0)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlp==0.2.0) (12.0.1)\n",
      "Requirement already satisfied: dill in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlp==0.2.0) (0.3.5.1)\n",
      "Requirement already satisfied: joblib in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers==3.0.0) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers==3.0.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers==3.0.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from click->nltk) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from packaging->transformers==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: six in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from sacremoses->transformers==3.0.0) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.0)\n",
      "/home/matheus/anaconda3/envs/repro/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /home/matheus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Requirement already satisfied: transformers[torch] in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: filelock in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: numpy in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: sentencepiece in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (0.2.0)\n",
      "Requirement already satisfied: requests in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (2.28.1)\n",
      "Requirement already satisfied: sacremoses in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: tokenizers==0.8.0-rc4 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (0.8.0rc4)\n",
      "Requirement already satisfied: packaging in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: torch in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from packaging->transformers[torch]) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers[torch]) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests->transformers[torch]) (2022.9.14)\n",
      "Requirement already satisfied: six in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from sacremoses->transformers[torch]) (1.16.0)\n",
      "Requirement already satisfied: click in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from sacremoses->transformers[torch]) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from sacremoses->transformers[torch]) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from torch->transformers[torch]) (4.3.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from torch->transformers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from torch->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from torch->transformers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from torch->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->transformers[torch]) (63.4.1)\n",
      "Requirement already satisfied: wheel in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->transformers[torch]) (0.37.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from click->sacremoses->transformers[torch]) (3.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers[torch]) (3.8.0)\n",
      "Requirement already satisfied: dill==0.3.5.1 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (0.3.5.1)\n",
      "Collecting git+https://github.com/Maluuba/nlg-eval.git@master\n",
      "  Cloning https://github.com/Maluuba/nlg-eval.git (to revision master) to /tmp/pip-req-build-rc2zprzh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Maluuba/nlg-eval.git /tmp/pip-req-build-rc2zprzh\n",
      "  Resolved https://github.com/Maluuba/nlg-eval.git to commit 2ab4528fad5548315cf61e40c2249fec8c8ad233\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=6.3 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (8.0.4)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (3.7)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (1.21.5)\n",
      "Requirement already satisfied: psutil>=5.6.2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (2.28.1)\n",
      "Requirement already satisfied: six>=1.11 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (1.16.0)\n",
      "Requirement already satisfied: Cython>=0.28.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (0.29.32)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (1.0.2)\n",
      "Collecting gensim~=3.8.3\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Theano>=0.8.1\n",
      "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.24 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nlg-eval==2.4.1) (4.64.1)\n",
      "Collecting xdg\n",
      "  Downloading xdg-6.0.0-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from click>=6.3->nlg-eval==2.4.1) (3.10.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from gensim~=3.8.3->nlg-eval==2.4.1) (5.2.1)\n",
      "Requirement already satisfied: joblib in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nltk>=3.4.5->nlg-eval==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from nltk>=3.4.5->nlg-eval==2.4.1) (2022.7.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests>=2.19->nlg-eval==2.4.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests>=2.19->nlg-eval==2.4.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests>=2.19->nlg-eval==2.4.1) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from requests>=2.19->nlg-eval==2.4.1) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from scikit-learn>=0.17->nlg-eval==2.4.1) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from importlib-metadata->click>=6.3->nlg-eval==2.4.1) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages (from importlib-metadata->click>=6.3->nlg-eval==2.4.1) (3.8.0)\n",
      "Building wheels for collected packages: nlg-eval, Theano\n",
      "  Building wheel for nlg-eval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nlg-eval: filename=nlg_eval-2.4.1-py3-none-any.whl size=98924375 sha256=67d7905a1545ace4d2a7e0d36a573dc0a2991e00439977cbe16ed98d7f99cdfd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q3uro18d/wheels/08/20/df/33ced66932f198c4323042d18ff1c2db9b9716369f0de4afb4\n",
      "  Building wheel for Theano (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Theano: filename=Theano-1.0.5-py3-none-any.whl size=2668109 sha256=86c0c453b5244e22a16781556c75eaeb6e79003f3c6c21a24f02ad7e5fdbbc96\n",
      "  Stored in directory: /home/matheus/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
      "Successfully built nlg-eval Theano\n",
      "Installing collected packages: xdg, Theano, gensim, nlg-eval\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed Theano-1.0.5 gensim-3.8.3 nlg-eval-2.4.1 xdg-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.0 nltk nlp==0.2.0\n",
    "!python -m nltk.downloader punkt\n",
    "!pip install transformers[torch]\n",
    "!pip install dill==0.3.5.1\n",
    "!pip install git+https://github.com/Maluuba/nlg-eval.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clonando o repositório com o código base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL7YmZyypOTJ",
    "outputId": "20bafceb-412f-4cb8-9258-b1df2604e2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'question_generation'...\n",
      "remote: Enumerating objects: 268, done.\u001b[K\n",
      "remote: Total 268 (delta 0), reused 0 (delta 0), pack-reused 268\u001b[K\n",
      "Receiving objects: 100% (268/268), 299.04 KiB | 1.86 MiB/s, done.\n",
      "Resolving deltas: 100% (140/140), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fqyJ4x8qHWo",
    "outputId": "84f19153-79d6-477f-fd70-3cacf8874c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matheus/Documentos/fpcc2-reprodutibilidade/question_generation\n"
     ]
    }
   ],
   "source": [
    "%cd question_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYAKsyG_y3ht",
    "outputId": "29a9748f-8aaf-494b-8cfe-c13b6c3e2709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/03/2024 21:39:38 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /home/matheus/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n",
      "07/03/2024 21:39:38 - INFO - transformers.tokenization_utils -   Adding <sep> to the vocabulary\n",
      "07/03/2024 21:39:38 - INFO - transformers.tokenization_utils -   Adding <hl> to the vocabulary\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Checking data/squad_multitask/squad_multitask.py for additional imports.\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Found main folder for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Found specific version folder for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Found script file from data/squad_multitask/squad_multitask.py to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/squad_multitask.py\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Found dataset infos file from data/squad_multitask/dataset_infos.json to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/dataset_infos.json\n",
      "07/03/2024 21:39:38 - INFO - nlp.load -   Found metadata file for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/squad_multitask.json\n",
      "[nltk_data] Downloading package punkt to /home/matheus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "07/03/2024 21:39:39 - INFO - nlp.info -   Loading Dataset Infos from /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Overwrite dataset info from restored data version.\n",
      "07/03/2024 21:39:39 - INFO - nlp.info -   Loading Dataset info from /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Reusing dataset squad_multitask (/home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0)\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Constructing Dataset for split train, from /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Checking data/squad_multitask/squad_multitask.py for additional imports.\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Found main folder for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Found specific version folder for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Found script file from data/squad_multitask/squad_multitask.py to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/squad_multitask.py\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Found dataset infos file from data/squad_multitask/dataset_infos.json to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/dataset_infos.json\n",
      "07/03/2024 21:39:39 - INFO - nlp.load -   Found metadata file for dataset data/squad_multitask/squad_multitask.py at /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd/squad_multitask.json\n",
      "07/03/2024 21:39:39 - INFO - nlp.info -   Loading Dataset Infos from /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlp/datasets/squad_multitask/79eda69e803ef0edf75970022ebdffc3b92a11d258088c947b94a6d01b2cddfd\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Overwrite dataset info from restored data version.\n",
      "07/03/2024 21:39:39 - INFO - nlp.info -   Loading Dataset info from /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Reusing dataset squad_multitask (/home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0)\n",
      "07/03/2024 21:39:39 - INFO - nlp.builder -   Constructing Dataset for split validation, from /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0\n",
      "07/03/2024 21:39:39 - INFO - numexpr.utils -   Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "07/03/2024 21:39:39 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n",
      "07/03/2024 21:39:39 - INFO - nlp.arrow_dataset -   Loading cached processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-e4cb15461534045deaf26812adc48fae.arrow\n",
      "07/03/2024 21:39:39 - INFO - nlp.arrow_dataset -   Loading cached processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-6dce60ddfa01886630bd7842279f8844.arrow\n",
      "07/03/2024 21:39:39 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-ba290ae2a38077dde0216affad33f1c5.arrow\n",
      "87599it [00:01, 45881.46it/s]\n",
      "07/03/2024 21:39:41 - INFO - nlp.arrow_writer -   Done writing 87599 examples in 77276159 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-ba290ae2a38077dde0216affad33f1c5.arrow.\n",
      "07/03/2024 21:39:41 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-cdb243c8fbb90c4b7bff9d7a6cc31a30.arrow\n",
      "87599it [00:01, 44541.34it/s]\n",
      "07/03/2024 21:39:43 - INFO - nlp.arrow_writer -   Done writing 87599 examples in 76224971 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-cdb243c8fbb90c4b7bff9d7a6cc31a30.arrow.\n",
      "07/03/2024 21:39:43 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-9affa53f9d34fec1507a5565ecd3f0c6.arrow\n",
      "100%|███████████████████████████████████████████| 88/88 [01:18<00:00,  1.12it/s]\n",
      "07/03/2024 21:41:01 - INFO - nlp.arrow_writer -   Done writing 87599 examples in 817312511 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-9affa53f9d34fec1507a5565ecd3f0c6.arrow.\n",
      "07/03/2024 21:41:01 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-7876b6d3002c6d9de73ba344361033e3.arrow\n",
      "10570it [00:00, 47215.14it/s]\n",
      "07/03/2024 21:41:02 - INFO - nlp.arrow_writer -   Done writing 10570 examples in 9590642 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-7876b6d3002c6d9de73ba344361033e3.arrow.\n",
      "07/03/2024 21:41:02 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-4647c20ea57228e01a498babd2c0e48a.arrow\n",
      "10570it [00:00, 45053.34it/s]\n",
      "07/03/2024 21:41:02 - INFO - nlp.arrow_writer -   Done writing 10570 examples in 9463802 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-4647c20ea57228e01a498babd2c0e48a.arrow.\n",
      "07/03/2024 21:41:02 - INFO - nlp.arrow_dataset -   Caching processed dataset at /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-c70e28d963625b9bef8285c667c80c8b.arrow\n",
      "100%|███████████████████████████████████████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "07/03/2024 21:41:11 - INFO - nlp.arrow_writer -   Done writing 10570 examples in 98886002 bytes /home/matheus/.cache/huggingface/datasets/squad_multitask/highlight_qg_format/1.0.0/cache-c70e28d963625b9bef8285c667c80c8b.arrow.\n",
      "07/03/2024 21:41:11 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
      "07/03/2024 21:41:11 - INFO - nlp.arrow_dataset -   Set __getitem__(key) output type to torch for ['source_ids', 'target_ids', 'attention_mask'] columns  (when key is int or slice) and don't output other (un-formated) columns.\n",
      "07/03/2024 21:41:17 - INFO - __main__ -   saved train dataset at data/train_data_qg_hl_t5.pt\n",
      "07/03/2024 21:41:17 - INFO - __main__ -   saved validation dataset at data/valid_data_qg_hl_t5.pt\n",
      "07/03/2024 21:41:17 - INFO - __main__ -   saved tokenizer at t5_qg_tokenizer\n"
     ]
    }
   ],
   "source": [
    "!python prepare_data.py \\\n",
    "    --task qg \\\n",
    "    --model_type t5 \\\n",
    "    --dataset_path data/squad_multitask/ \\\n",
    "    --qg_format highlight_qg_format \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 32 \\\n",
    "    --train_file_name train_data_qg_hl_t5.pt \\\n",
    "    --valid_file_name valid_data_qg_hl_t5.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo\n",
    "- Originalmente o autor utiliza o batch size de 32 para o treinamento, porém, por limites de memória de GPU, tivemos que diminuir o batch-size para 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q3GR6Q3-qAb9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python run_qg.py \\\n",
    "    --model_name_or_path t5-small \\\n",
    "    --model_type t5 \\\n",
    "    --tokenizer_name_or_path t5_qg_tokenizer \\\n",
    "    --output_dir t5-small-qg-hl \\\n",
    "    --train_file_path data/train_data_qg_hl_t5.pt \\\n",
    "    --valid_file_path data/valid_data_qg_hl_t5.pt \\\n",
    "    --per_device_train_batch_size 28 \\\n",
    "    --per_device_eval_batch_size 28 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --seed 42 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --logging_steps 100\n",
    "print(\"acabou o treinamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n4HgrEE7qGDA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 331/331 [04:50<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "!python eval.py \\\n",
    "    --model_name_or_path /home/matheus/Documentos/fpcc2-reprodutibilidade/question_generation/t5-small-qg-hl \\\n",
    "    --valid_file_path data/valid_data_qg_hl_t5.pt \\\n",
    "    --model_type t5 \\\n",
    "    --num_beams 4 \\\n",
    "    --max_decoding_length 32 \\\n",
    "    --output_path hypothesis_t5-small-qg-hl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matheus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\u001b[31mInstalling to /home/matheus/Documentos/fpcc2-reprodutibilidade/\u001b[0m\n",
      "\u001b[31mIn case of incomplete downloads, delete the directory and run `nlg-eval --setup /home/matheus/Documentos/fpcc2-reprodutibilidade/' again.\u001b[0m\n",
      "Downloading http://nlp.stanford.edu/software/stanford-corenlp-full-2015-12-09.zip to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlgeval.\n",
      "Downloading https://raw.githubusercontent.com/robmsmt/glove-gensim/4c2224bccd61627b76c50a5e1d6afd1c82699d22/glove2word2vec.py to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlgeval/word2vec.\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/dictionary.txt to /home/matheus/Documentos/fpcc2-reprodutibilidade/.Downloading http://nlp.stanford.edu/data/glove.6B.zip to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "\n",
      "glove2word2vec.py: 100%|█████████████████| 1.00/1.00 [00:00<00:00, 413 chunks/s]\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/utable.npy to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "utable.npy:   0%|                             | 0.00/2.23k [00:00<?, ? chunks/s]ERROR:root:Error downloading file, will retry in 60s.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matheus/anaconda3/envs/repro/bin/nlg-eval\", line 40, in _download_file\n",
      "    r.raise_for_status()\n",
      "  File \"/home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Temporarily Unavailable for url: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2015-12-09.zip\n",
      "dictionary.txt: 100%|███████████████████| 8.00/8.00 [00:02<00:00, 3.30 chunks/s]\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/btable.npy to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "btable.npy:  14%|███▎                   | 320/2.23k [00:56<04:37, 6.90 chunks/s]Downloading http://nlp.stanford.edu/software/stanford-corenlp-full-2015-12-09.zip to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlgeval.\n",
      "stanford-corenlp-full-2015-12-09.zip: 100%|█| 385/385 [01:12<00:00, 5.28 chunks/\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/uni_skip.npz to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "glove.6B.zip: 100%|███████████████████████| 823/823 [02:48<00:00, 4.90 chunks/s]\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "uni_skip.npz.pkl: 100%|█████████████████| 1.00/1.00 [00:00<00:00, 86.8 chunks/s]\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/bi_skip.npz to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "bi_skip.npz: 100%|████████████████████████| 276/276 [00:39<00:00, 6.91 chunks/s]\n",
      "Downloading http://mirror.nubenum.de/www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl to /home/matheus/Documentos/fpcc2-reprodutibilidade/.\n",
      "bi_skip.npz.pkl: 100%|██████████████████| 1.00/1.00 [00:00<00:00, 81.5 chunks/s]\n",
      "Downloading https://raw.githubusercontent.com/moses-smt/mosesdecoder/b199e654df2a26ea58f234cbb642e89d9c1f269d/scripts/generic/multi-bleu.perl to /home/matheus/anaconda3/envs/repro/lib/python3.7/site-packages/nlgeval/multibleu.\n",
      "multi-bleu.perl: 100%|███████████████████| 1.00/1.00 [00:00<00:00, 334 chunks/s]\n",
      "uni_skip.npz: 100%|███████████████████████| 634/634 [01:28<00:00, 7.20 chunks/s]\n",
      "btable.npy: 100%|█████████████████████| 2.23k/2.23k [04:59<00:00, 7.46 chunks/s]\n",
      "utable.npy: 100%|█████████████████████| 2.23k/2.23k [05:06<00:00, 7.29 chunks/s]\n",
      "2024-07-04 00:57:35,666 : MainThread : INFO : 400000 lines with 300 dimensions\n",
      "2024-07-04 00:57:38,538 : MainThread : INFO : Model /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.txt successfully created !!\n",
      "2024-07-04 00:57:38,539 : MainThread : INFO : loading projection weights from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.txt\n",
      "2024-07-04 00:58:22,753 : MainThread : INFO : loaded (400000, 300) matrix from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.txt\n",
      "2024-07-04 00:58:22,753 : MainThread : INFO : precomputing L2-norms of word weight vectors\n",
      "2024-07-04 00:58:24,642 : MainThread : INFO : Most similar to king are: [('queen', 0.6336469054222107), ('prince', 0.619662344455719), ('monarch', 0.5899620056152344), ('kingdom', 0.5791267156600952), ('throne', 0.5606487989425659), ('ii', 0.5562329292297363), ('iii', 0.5503199100494385), ('crown', 0.5224862694740295), ('reign', 0.5217353701591492), ('kings', 0.5066400766372681)]\n",
      "2024-07-04 00:58:24,642 : MainThread : INFO : Similarity score between woman and man is 0.69986635 \n",
      "2024-07-04 00:58:24,642 : MainThread : INFO : Finished running --setup\n",
      "2024-07-04 00:58:24,805 : MainThread : INFO : loading projection weights from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.txt\n",
      "2024-07-04 00:59:09,253 : MainThread : INFO : loaded (400000, 300) matrix from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.txt\n",
      "2024-07-04 00:59:09,254 : MainThread : INFO : saving Word2VecKeyedVectors object under /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin, separately None\n",
      "2024-07-04 00:59:09,254 : MainThread : INFO : storing np array 'vectors' to /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin.vectors.npy\n",
      "2024-07-04 00:59:09,798 : MainThread : INFO : not storing attribute vectors_norm\n",
      "2024-07-04 00:59:10,711 : MainThread : INFO : saved /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin\n",
      "2024-07-04 00:59:10,711 : MainThread : INFO : loading Word2VecKeyedVectors object from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin\n",
      "2024-07-04 00:59:12,429 : MainThread : INFO : loading vectors from /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin.vectors.npy with mmap=r\n",
      "2024-07-04 00:59:12,452 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2024-07-04 00:59:12,452 : MainThread : INFO : loaded /home/matheus/Documentos/fpcc2-reprodutibilidade/glove.6B.300d.model.bin\n",
      "WARNING: could not read rc.json in /home/matheus/.config/nlgeval, overwriting\n"
     ]
    }
   ],
   "source": [
    "!nlg-eval --setup /home/matheus/Documentos/fpcc2-reprodutibilidade/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas reportadas no artigo\n",
    "![](imgs/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que as métricas reportadas pelo autor são muito parecidas. A diferença pode se dar pela alteração no parâmetro de batch_size na etapa de treinamento\n",
    "  \n",
    "|         | Autor | Esse Experimento |\n",
    "|---------|-------|------------------|\n",
    "| BLEU-4  | 18.5  | 19.0             |\n",
    "| METEOR  | 24.9  | 25.3             |\n",
    "| ROUGE-L | 40.1  | 40.8             |\n",
    "\n",
    "As métricas que obtivemos são superiores as reportadas pelo autor, o que indica que o artigo não sofre com problemas de reprodutibilidade.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing data from /home/matheus/Documentos/fpcc2-reprodutibilidade/\u001b[0m\n",
      "\u001b[32mIn case of broken downloads, remove the directory and run setup again.\u001b[0m\n",
      "Bleu_1: 0.419301\n",
      "Bleu_2: 0.310191\n",
      "Bleu_3: 0.240364\n",
      "Bleu_4: 0.190926\n",
      "METEOR: 0.253340\n",
      "ROUGE_L: 0.408245\n",
      "CIDEr: 1.805433\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0,4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0,9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1,2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0,5 sec].\n",
      "Threads( StanfordCoreNLP ) [01:15.607 minutes]\n",
      "Threads( StanfordCoreNLP ) [5.73 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [01:13.35 minutes]\n",
      "Threads( StanfordCoreNLP ) [2.364 seconds]\n",
      "SPICE evaluation took: 2.791 min\n",
      "SPICE: 0.379463\n"
     ]
    }
   ],
   "source": [
    "!nlg-eval --hypothesis=hypothesis_t5-small-qg-hl.txt --references=data/references.txt --no-skipthoughts --no-glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
